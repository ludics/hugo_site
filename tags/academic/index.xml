<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic on Carpe Diem</title>
    <link>https://ludics.github.io/tags/academic/</link>
    <description>Recent content in Academic on Carpe Diem</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>leonludics@gmail.com (Lu Di)</managingEditor>
    <webMaster>leonludics@gmail.com (Lu Di)</webMaster>
    <lastBuildDate>Thu, 28 Mar 2019 15:20:36 +0800</lastBuildDate>
    
	<atom:link href="https://ludics.github.io/tags/academic/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Paper Reading on Face Recognition</title>
      <link>https://ludics.github.io/post/paper-read-on-face-recognition/</link>
      <pubDate>Thu, 28 Mar 2019 15:20:36 +0800</pubDate>
      <author>leonludics@gmail.com (Lu Di)</author>
      <guid>https://ludics.github.io/post/paper-read-on-face-recognition/</guid>
      <description>ArcFace: Additive Angular Margin Loss for Deep Face Recognition Abstract Design of loss function that enhance discriminative power.
ArcFace: Additive Angular Margin Loss, has a clear geometric interpretation due to the geodesic distance on the hypersphere.
Introduction DCNNs map face image into a feature that has small intra-class and large inter-class distance.
Two lines to train:
 multi-class classifier, separates different identities using softmax learn an embedding, triplet loss(anchor, positive, negative)  ==&amp;gt; Both have drawbacks</description>
    </item>
    
    <item>
      <title>Paper Reading on Model Compression</title>
      <link>https://ludics.github.io/post/2019-03-23-read-paper/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      <author>leonludics@gmail.com (Lu Di)</author>
      <guid>https://ludics.github.io/post/2019-03-23-read-paper/</guid>
      <description>A Survey of Model Compression and Acceleration for Deep Neural Networks Abstract Deep convolutional neural networks (CNNs) have recently achieved great success in many visual recognition tasks. However, existing deep neural network models are computationally expensive and memory intensive, hindering their deployment in devices with low memory resources or in applications with strict latency requirements. Therefore, a natural thought is to perform model compression and acceleration in deep networks without significantly decreasing the model performance.</description>
    </item>
    
  </channel>
</rss>